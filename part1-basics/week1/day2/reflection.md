# Reflection – Week 1, Day 2: AI Ethics, Security & Responsible Use

## Update
Completed Day 2 covering security risks, code ownership, bias, when not to use AI, and organizational guidelines.

---

## Reflection – AI Ethics, Security & Responsible Use

### What I Learned
- The 5 major security risks when using AI tools (data leakage, vulnerable code, PII disclosure, credential exposure, IP leakage)
- AI code ownership is legally unclear and GPL contamination is a real risk
- AI reflects training data biases (stereotypes, accessibility gaps, default assumptions)

### What Surprised Me
- How easy it is to accidentally share sensitive data in prompts
- The legal gray area around AI-generated code ownership
- How often AI-generated code lacks accessibility features

### How I Will Use This
- Always sanitizing prompts before sharing with AI tools (example.com, user@example.com)
- Never using AI for security-critical code (auth, crypto, password hashing)
- Reviewing all AI code for bias, accessibility, and security issues
- Maintaining the 70/30 rule: 70% manual coding for learning, 30% AI assistance
