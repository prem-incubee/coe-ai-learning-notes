# Reflection – Week 1, Day 1: AI/LLM Fundamentals & Prompt Engineering

## Update
Completed Day 1 covering LLM fundamentals, tokens, context windows, and prompt engineering basics.

---

## Reflection – LLM Fundamentals & Prompt Engineering

### What I Learned
- How LLMs work at a high level (3-stage training process)
- Why prompt quality matters (specificity and context are crucial)
- How tokens and context windows affect results and costs

### What Surprised Me
- Small wording changes drastically affect output quality
- Examples are more effective than long explanations (few-shot learning)
- LLMs can confidently hallucinate facts and citations

### How I Will Use This
- Writing clearer prompts with explicit instructions and context
- Using few-shot learning for structured coding tasks
- Verifying critical information instead of blindly trusting outputs
